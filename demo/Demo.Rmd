---
title: "Ploidetect Example Case"
author: "Luka Culibrk"
date: "2/11/2019"
output: 
  github_document:
    pandoc_args: --webtex
---

```{r setup, include=FALSE}
library(devtools)
devtools::load_all(pkg = "../", reset = T)
#install_github("lculibrk/Ploidetect-package")
library(Ploidetect)
```

## Data import

First we import the data, formatted as discussed in the README.md. This data is a metastatic tumor biopsy sequenced as part of the Personalized Oncogenomics Project. 

```{r}
dat <- read.table("examplePOG.txt", stringsAsFactors = F, header = T)
str(dat)
```

## Running Ploidetect

Now we run Ploidetect by calling ```ploidetect()```, and supplying the indices for the columns in our data.

```{r, echo=FALSE}
result <- ploidetect(all_data = dat, normal = 2, tumour = 1, avg_allele_freq = 3, window_id = 4, window_size = 5, GC = 6, verbose = F, CNA_call = F)
```

Let's get a look at how the results look.

```{r}
purity_calls <- result$TC_calls
plots <- result$plots
knitr::kable(purity_calls)
plots[[3]]
```

## TC_calls object

ploidetect() returns a list of three objects; TC_calls, or "tumor content calls" describes the models that Ploidetect has used to estimate tumour purity using a variety of different assumptions. It is ordered by the strength of the model, so the first model is most likely to describe the true tumour purity. In this case the purity is predicted to be `r round(purity_calls$tumour_purity[1], digits = 2) * 100`%. 

There are `r ncol(purity_calls)` columns in the TC_calls object. The columns correspond to the following values:

* reads_per_copy: The number of reads in a genomic bin that are expected to come from a single copy of the genome

* zero_copy_depth: The number of reads in a genomic bin which is homozygously deleted in the tumor sample. This is the number of reads coming from the contaminating normal.

* Ploidy: the estimated most common copy number state in the genome.

* tumour_purity: the tumour purity

* lowest_peak_CN: used in Ploidetect's modeling. Corresponds to the copy number of the lowest well-represented copy number state in the genome

* maf_error: The median difference between expected and observed germline-heterozygous SNP allele frequencies

* CN_diff: Used in Ploidetect's modeling. See below for more information.

* Comparator: Used in Ploidetect's modeling. See below for more information.

* Model_error: The error computed by Ploidetect for this model. Used to rank models.

* Avg_ploidy: The mean copy number of the genome.

* Unmatchedpct: An estimate of the proportion of the genome that was excluded from the model fit. See below for more information.

## A brief lesson in NGS copy number variation data

Copy number variation is a common type of mutation in most cancers. To explain the methodology, let's use a simple toy genome to go over a few concepts that Ploidetect uses. First, we generate a small toy genome with a decent amount of chromosomal instability.

```{r}
set.seed(42069)
expand.segments <- function(copynumbers){
  out_cns <- c()
  out_segs <- c()
  for(segment in 1:length(copynumbers)){
    new_size <- round(rnorm(n = 1, mean = 20, sd = 4), digits = 0)
    out_cns <- c(out_cns, rep(copynumbers[segment], times = max(1, new_size)))
    out_segs <- c(out_segs, rep(segment, times = max(1, new_size)))
  }
  out <- data.frame("copynumber" = out_cns, "segment" = out_segs)
  return(out)
}

genome_positions <- 1:10
genome_copynumber <- round(rnorm(n = length(genome_positions), mean = 2, sd = 1), digits = 0)
genome_obj <- expand.segments(genome_copynumber)
genome_obj$start <- 1:nrow(genome_obj)
genome_obj$end <- genome_obj$start + 1

ggplot(genome_obj, aes(x = start, y = copynumber)) + geom_point() + theme_bw()

```

Okay. So we have a genome. Now let's simulate depth based on the copy numbers we've generated. We'll have the counts follow a normal distribution for simplicity, and assume that the depth is 40x (ie. two-copy regions get 40 aligned reads, one-copy regions get 20, and so forth)

```{r}
set.seed(42069)
genome_obj$counts <- NA
for(segment in genome_obj$segment){
  current_segment <- genome_obj[genome_obj$segment == segment,]
  genome_obj$counts[genome_obj$segment == segment] <- rnorm(n = nrow(current_segment), mean = 20 * current_segment$copynumber[1])
}
ggplot(genome_obj, aes(x = start, y = counts, color = factor(copynumber))) + geom_point() + theme_bw() + scale_color_viridis(discrete = T)
```

In this example, the take-home message is that the difference in depth between a one-copy region and a two-copy region is the same as the difference in depth between a two and three-copy region - in this case, the difference is 20. Here's another way to look at the copy number landscape of this genome:

```{r}
ggplot(genome_obj, aes(x = counts)) + geom_density() + scale_x_continuous(limits = c(0, 100)) + theme_bw()
```

The density plot communicates the relative quantity and approximate depth of the copy number variants in this genome. In this example genome, we have assumed that there is zero normal contamination. In a real tumour biopsy, this is almost never the case.

Consider that the total reads that align to a given locus can be represented as such:

$\sum reads = reads_t + reads_n$

Where $reads_t$ is the number tumour reads and $reads_n$ is the amount of normal reads.

In the case of 50% tumour purity, the read depth of a locus with equal copy number in both tumour and normal should be equal:

$\sum reads = reads_t + reads_n = 2reads_t = 2reads_n$

Or where the copy number is inequal, it is a weighted average ($C_n$ for normal copy number and $C_t$ for tumour copy number):

$\sum reads = \frac{C_treads_t + C_nreads_n}{2}$

Since (nearly) the entire normal genome should be diploid, we can simplify the above by removing $C_n$:

$\sum reads = \frac{C_treads_t + 2reads_n}{2} = \frac{C_treads_t}{2} + reads_n$

The conclusion of this (long-winded) string of equations is that for any given locus, the number of reads that originate from contaminating normal is a constant, $reads_n$. Since $reads_n$ corresponds to the depth of a two-copy region, we can get the degree of normal contamination ($\alpha$) from the following equation:

$\alpha = \frac{reads_n}{\sum reads}$

Where $\sum reads$ was measured at copy number two. 

Going back to the toy genome, let's add some contaminating counts - we'll aim for 50% tumour purity here.

```{r}
set.seed(42069)
genome_obj$counts <- genome_obj$counts/2 + rnorm(nrow(genome_obj), mean = 20)
ggplot(genome_obj, aes(x = start, y = counts, color = factor(copynumber))) + geom_point() + theme_bw() + scale_color_viridis(discrete = T)
ggplot(genome_obj, aes(x = counts)) + geom_density() + scale_x_continuous(limits = c(0, 100), breaks = seq(from = 0, to = 100, by = 10)) + theme_bw()
```

First, how do we determine $reads_n$?

Going back to $\sum reads = reads_t + reads_n$, we just have to find where $reads_t = 0$, which occurs at loci that are homozygously deleted. In our toy case (and in many tumour biopsies), there are no homozygously deleted regions. However, we can predict where it will be. From the above plot, we can see that the difference in depth between each copy number is about 10 counts. This information can be used to determine the depth of a zero-copy region using regression:

```{r}
fit <- lm(formula = counts~copynumber, data = genome_obj)
predict(object = fit, data.frame("copynumber" = 0))
```

Now $\sum reads$ for two-copy can be challenging to find, since we need to identify which loci are two-copy. In this example, we have it in ```genome_obj```

```{r}
genome_obj %>% group_by(copynumber) %>% dplyr::summarise("mean_cov" = mean(counts))
```

Now we just plug these numbers in:

```{r}
20.4/40.1
```

Tumour purity is 50.9% for our toy example.

The above is the methodology that Ploidetect uses to determine tumour purity. Let's do the estimate for the cancer case ourselves.

```{r}
result$plots[[1]]
```

CN=2 occurs at approximately 13000 depth, and CN=1 occurs at about 11000. CN=0 must occur at about 9000. As an aside, Ploidetect knows the copy number state of the peaks in the histogram by fitting the SNP allele frequencies indicted by "MAF = x" in the plot. 

```{r}
1 - 9000/13000
```

Eyeballing it gives us 31% purity, and Ploidetect predicted 39%.

However, determining the depth of a homozygous deletion may be challenging the case of a messy genome. Notably, in cases of subclonal copy number variation, not all peaks in the density histogram correspond to integer copy number states. In these cases, it is challenging to estimate the depth difference between different integer copy number states. To illustrate this, here's another metastatic tumour, however this one contains subclonal copy number variation, and we'll go through Ploidetect's process to explain how it manages to determine the purity of this biopsy.

```{r}
clonalcase <- read.table("clonal_example.txt", sep = "\t", header = T, stringsAsFactors = F)
str(clonalcase)
```

Here we're going to go through Ploidetect's internals to demonstrate what it's doing, step by step. First let's set the variables that would otherwise be handled by the parameters of ploidetect()

```{r}
all_data <- clonalcase
normal = 2
tumour = 1
avg_allele_freq =3
window_id = 4
window_size = 5
GC = 6
verbose = F
```

Note that you won't be able to call these functions yourself as they aren't exported by the namespace of the package.

First, we call ploidetect_preprocess, which performs basic preprocessing of the data. It corrects for lingering GC biases using a loess fit and also corrects the read depth using the normal read depth, since using constant depth bins can fail at the terminal end of the chromsome due to being truncated by the end of the chromosome. We get three objects, one of which is important for our sake.

```{r}
preprocess_output <- ploidetect_preprocess(all_data = all_data)
str(preprocess_output)
```



```{r}
filtered <- preprocess_output$x
maxpeak <- preprocess_output$maxpeak
highoutliers <- preprocess_output$highoutliers
```


filtered contains the corrected and filtered read depths for our data. Let's compare before and after (and some filtering to visualize the difference more easily).


```{r}
filtered %>% filter (y_raw < 50000) %>% ggplot(aes(x = size)) + geom_point(aes(y = y_raw), alpha = 0.05, size = 0.1)
filtered %>% filter (y_raw < 50000) %>% ggplot(aes(x = size)) + geom_point(aes(y = residual), alpha = 0.05, size = 0.1)
```

It's not much, but we have reduced the variation in the read depth data somewhat. If you were wondering, highoutliers contains exceptionally high depth outliers that are either caused by sequencing error or other causes, and we exclude these bins to limit their interference on the modeling. maxpeak is the most common read depth that we observe in the data.


Ploidetect uses a kernel density estimation to find peaks in the depth histogram. We use a simple heuristic to get a decent bandwidth for peak calling.


```{r}
bw = maxpeak/80
```

Next, we need to call peaks in the density histogram. The histogram, for reference:

```{r}
plot(density(filtered$residual, bw = bw, n = nrow(filtered$residual)))
```

Ploidetect calls peaks using a simple derivative approach. It takes the second derivative of the kernel density estimation and detects the point where the sign goes negative.

```{r}
library(kedd)
plot(dkde(filtered$residual, deriv.order = 2, h = bw))
```

Of course, since we used a simple heuristic for bandwidth, we should probably throw another heuristic in for good measure. What if we detect only one peak in the data? Either there is no copy number variation, or Ploidetect needs to reduce the bandwidth. So as a first pass Ploidetect filters the data relatively stringently, by using a quantile filter from the 1st to 99th percentiles of read depth and calls peaks. Don't worry too much about what all of the variables mean.

```{r}
(allPeaks <- peakcaller(filtered[findInterval(filtered$residual, vec = quantile(filtered$residual, probs = c(0.01, 0.99))) == 1,], bw))
```

So we've called more than one peak, we can continue with the same bandwidth, but a less stringent filter (0.1st percentile and 99.9th). If Ploidetect called only one then it would try again by halving the bandwidth

```{r}
if(nrow(allPeaks) == 1){
  warning("Zero peaks detected. Attempting peak calling with lower bandwidth")
  bw = bw/2
  allPeaks <- peakcaller(filtered[findInterval(filtered$residual, vec = quantile(filtered$residual, probs = c(0.01, 0.99))) == 1,], bw)
}

## Now we peak call with a much more permissive quantile filter
(allPeaks <- peakcaller(filtered[findInterval(filtered$residual, vec = quantile(filtered$residual, probs = c(0.001, 0.999))) == 1,], bw))
```

So you can see the less stringent filtering resulted in another peak being called. Next we do a bit of housekeeping and center the positions and read depths around zero

```{r}
filtered$residual <- filtered$residual - allPeaks$pos[1]
allPeaks$start <- allPeaks$start - allPeaks$pos[1]
allPeaks$end <- allPeaks$end - allPeaks$pos[1]
allPeaks$pos <- allPeaks$pos - allPeaks$pos[1]
```

next we need to do a bit of work with the allele frequency data. Specifically, we want to determine the SNP allele frequency that best represents each peak. This is done by ploidetect_processallpeaks. We also map the data to their respective peaks. This doesn't map them all, because peak boundaries end up being fairly conservative due to the kernel density approach. 

```{r}
output <- ploidetect_processallpeaks(filtered, allPeaks)
filtered <- output$filtered
allPeaks <- output$allPeaks
filtered %>% ggplot(aes(x = size, y = residual, color = peak)) + geom_point(size = 0.1, alpha = 0.1) + scale_color_viridis()
```

This is where Ploidetect presents you with its first plot:

```{r}
filteredforplot <- filtered[findInterval(filtered$residual, vec = quantile(filtered$residual, probs = c(0.01, 0.999))) <= 1,]
filteredforplot$residual <- filteredforplot$residual + maxpeak
plot <- ggplot(data = filteredforplot, mapping = aes_string(x = "size", y = "residual", color = "mafflipped")) + geom_point(size = 0.1, alpha = 0.1) +
  #xlab("Window size") + 
  xlab("Window size of constant-coverage bins") + 
  #ylab("Reads mapping to bins in Somatic") + 
  ylab("Normalized somatic read counts") + 
  #ggtitle(paste0("Coverage vs normalized bin size (Surrogate for Mappability + GC bias)")) + 
  ggtitle(paste0("Coverage Plot for Filtered and Normalised Data")) + 
  scale_colour_viridis(option = "plasma", name = "Major Allele\n Frequency") +
  #scale_x_continuous(limits = quantile(filtered$size, probs = c(0.05, 0.99))) +
  theme_bw(base_size = 12)
plot
```

And now it generates the density plot, which also illustrates the peaks that have been called in this density histogram

```{r}
den <- density(filteredforplot$residual, bw = bw)
dendf <- data.frame(x = den$x, y = den$y)
# Normalize the density to 0->1 range
dendf$y <- (dendf$y - min(dendf$y))/(max(dendf$y) - min(dendf$y))
plot <- ggplot(data = dendf, mapping = aes(x = x, y = y)) + geom_line() + 
  xlab("Normalized somatic read counts") + 
  ylab("Normalized Density") + 
  ggtitle(paste0("Kernel Density Estimate of Count Data")) + 
  geom_vline(data = allPeaks, aes(xintercept = pos + maxpeak), linetype = 2) + 
  geom_text(data = allPeaks, aes(x = pos + maxpeak, y = allPeaks$height + 0.05, label = paste0("MAF = ", round(mainmaf, digits = 3)))) +
  theme_bw()
plot
```

I've already told you that this case has subclonal copy number variation. Some clues to this are evident in the above plot. We see that there is a main peak which is tallest by height, as well as a number of others of varying heights. If we try the approach that was demonstrated with our toy example, we would be wrong. Let's demonstrate why by first assuming we can indeed try the original approach. Let's take a look at allPeaks, sorted by position

```{r}
allPeaks %>% arrange(pos)
maxpeak
```

The difference in depth between peak 3 and peak 4 (as defined by the npeak variable) is 1835. The depth of the main peak is 18840 (from maxpeak), and the allele frequency is close to 0.5, which tells us that this peak has an even number of copies. Under this assumption, this tumour must be tetraploid, with peak 1 corresponding to homozygous deletions. Going back to the earlier equations, this information gives us $reads_n = 18440 - 7472$ and $\sum reads = 18440 - 3726$. Using the equation for $\alpha$, we get a purity value of `r (18440-7472)/(18440-3726)`

```{r}
knitr::knit_exit()
#testMAF()
```

```{r}

## Unpack the output list from ploidetect_transform
allPeaks <- output$allPeaks
filtered <- output$filtered 
## Run processallpeaks
output <- ploidetect_processallpeaks(filtered, allPeaks)


```